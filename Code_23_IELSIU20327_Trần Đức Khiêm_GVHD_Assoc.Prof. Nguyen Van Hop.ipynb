{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "machine_pool = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15]\n",
    "\n",
    "# Danh sách các job ban đầu (jobs_initial)\n",
    "jobs_initial = {\n",
    "    1: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12}\n",
    "    ],\n",
    "    2: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12}\n",
    "    ],\n",
    "    3: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 1},\n",
    "        {'op_id': 2, 'candidate_machines': [6], 'processing_time': 8},\n",
    "        {'op_id': 3, 'candidate_machines': [6], 'processing_time': 8}\n",
    "    ],\n",
    "    4: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 7}\n",
    "    ],\n",
    "    5: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 1}\n",
    "    ],\n",
    "    6: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 1},\n",
    "        {'op_id': 2, 'candidate_machines': [6], 'processing_time': 8},\n",
    "        {'op_id': 3, 'candidate_machines': [6], 'processing_time': 8}\n",
    "    ],\n",
    "    7: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 7}\n",
    "    ],\n",
    "    8: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 1},\n",
    "        {'op_id': 2, 'candidate_machines': [6], 'processing_time': 8},\n",
    "        {'op_id': 3, 'candidate_machines': [6], 'processing_time': 8}\n",
    "    ],\n",
    "    9: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 7}\n",
    "    ],\n",
    "    10: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 7}\n",
    "    ],\n",
    "    11: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 7}\n",
    "    ],\n",
    "    12: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12}\n",
    "    ],\n",
    "    13: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12}\n",
    "    ],\n",
    "    14: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 1},\n",
    "        {'op_id': 2, 'candidate_machines': [6], 'processing_time': 8},\n",
    "        {'op_id': 3, 'candidate_machines': [6], 'processing_time': 8}\n",
    "    ],\n",
    "    15: [\n",
    "        {'op_id': 1, 'candidate_machines': [3, 4], 'processing_time': 1},\n",
    "        {'op_id': 2, 'candidate_machines': [7], 'processing_time': 43},\n",
    "        {'op_id': 3, 'candidate_machines': [5], 'processing_time': 43}\n",
    "    ],\n",
    "    16: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12},\n",
    "        {'op_id': 2, 'candidate_machines': [8], 'processing_time': 8}\n",
    "    ],\n",
    "    17: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12},\n",
    "        {'op_id': 2, 'candidate_machines': [8], 'processing_time': 12}\n",
    "    ],\n",
    "    18: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12},\n",
    "        {'op_id': 2, 'candidate_machines': [8], 'processing_time': 4}\n",
    "    ],\n",
    "    19: [\n",
    "        {'op_id': 1, 'candidate_machines': [8], 'processing_time': 3}\n",
    "    ],\n",
    "    20: [\n",
    "        {'op_id': 1, 'candidate_machines': [1, 2], 'processing_time': 12},\n",
    "        {'op_id': 2, 'candidate_machines': [12, 13], 'processing_time': 25}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# due_dates_initial: tất cả các job đều có due_date = 1200, sử dụng dict comprehension\n",
    "due_dates_initial = {i: 1200 for i in range(1, 51)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy simulated_annealing: tạo lịch trình ban đầu dưới dạng dictionary.\n",
    "def simulated_annealing(jobs, due_dates, lambda_tardiness=1.0, **kwargs):\n",
    "    # Khởi tạo thời gian sẵn sàng của các máy\n",
    "    machine_ready = {m: 0 for m in machine_pool}\n",
    "    schedule = {}\n",
    "    # Với mỗi job, duyệt các operation theo thứ tự\n",
    "    for job, ops in jobs.items():\n",
    "        job_ready = 0  # Thời gian job sẵn sàng cho operation tiếp theo\n",
    "        for i, op in enumerate(ops):\n",
    "            best_machine = None\n",
    "            best_start = None\n",
    "            best_finish = float('inf')\n",
    "            # Chọn máy trong candidate có thể bắt đầu sớm nhất\n",
    "            for m in op['candidate_machines']:\n",
    "                st = max(job_ready, machine_ready[m])\n",
    "                ft = st + op['processing_time']\n",
    "                if ft < best_finish:\n",
    "                    best_finish = ft\n",
    "                    best_start = st\n",
    "                    best_machine = m\n",
    "            schedule[(job, i)] = (best_start, best_finish, best_machine)\n",
    "            job_ready = best_finish\n",
    "            machine_ready[best_machine] = best_finish\n",
    "    makespan = max(ft for (st, ft, m) in schedule.values())\n",
    "    total_tardiness = sum(max(0, schedule[(job, i)][1] - due_dates[job])\n",
    "                          for job in jobs for i in range(len(jobs[job])))\n",
    "    cost = makespan + lambda_tardiness * total_tardiness\n",
    "    return None, schedule, makespan, total_tardiness, cost, None\n",
    "\n",
    "# Chuyển schedule dictionary sang list các event\n",
    "def schedule_dict_to_list(schedule_dict, jobs_info):\n",
    "    events = []\n",
    "    for (job, op_index), (s, f, m) in schedule_dict.items():\n",
    "        op_info = jobs_info[job]['operations'][op_index]\n",
    "        event = {\n",
    "            'job': job,\n",
    "            'op_index': op_index,\n",
    "            'start': s,\n",
    "            'finish': f,\n",
    "            'machine': m,\n",
    "            'op_id': op_info['op_id'],\n",
    "            'candidate_machines': op_info['candidate_machines']\n",
    "        }\n",
    "        events.append(event)\n",
    "    events = sorted(events, key=lambda e: (str(e['job']), e['op_index'], e['start']))\n",
    "    return events\n",
    "\n",
    "# Hàm tách schedule (list event) theo current_time\n",
    "def split_schedule_list(event_list, current_time, jobs_info):\n",
    "    finished_events = []\n",
    "    unfinished_jobs = {}\n",
    "    jobs_events = {}\n",
    "    for event in event_list:\n",
    "        jobs_events.setdefault(event['job'], []).append(event)\n",
    "    for job, events in jobs_events.items():\n",
    "        events = sorted(events, key=lambda e: (e['op_index'], e['start']))\n",
    "        ops_list = []\n",
    "        job_ready = None\n",
    "        for event in events:\n",
    "            if event['finish'] <= current_time:\n",
    "                finished_events.append(event)\n",
    "                job_ready = event['finish']\n",
    "            elif event['start'] < current_time < event['finish']:\n",
    "                finished_part = event.copy()\n",
    "                finished_part['finish'] = current_time\n",
    "                finished_events.append(finished_part)\n",
    "                remaining_time = event['finish'] - current_time\n",
    "                unfinished_op = {\n",
    "                    'op_index': event['op_index'],\n",
    "                    'op_id': event['op_id'],\n",
    "                    'candidate_machines': event['candidate_machines'],\n",
    "                    'processing_time': remaining_time\n",
    "                }\n",
    "                ops_list.append(unfinished_op)\n",
    "                job_ready = current_time\n",
    "                total_ops = len(jobs_info[job]['operations'])\n",
    "                for op_index in range(event['op_index']+1, total_ops):\n",
    "                    op = jobs_info[job]['operations'][op_index]\n",
    "                    new_op = {\n",
    "                        'op_index': op_index,\n",
    "                        'op_id': op['op_id'],\n",
    "                        'candidate_machines': op['candidate_machines'],\n",
    "                        'processing_time': op['processing_time']\n",
    "                    }\n",
    "                    ops_list.append(new_op)\n",
    "                break\n",
    "            else:\n",
    "                unfinished_op = {\n",
    "                    'op_index': event['op_index'],\n",
    "                    'op_id': event['op_id'],\n",
    "                    'candidate_machines': event['candidate_machines'],\n",
    "                    'processing_time': event['finish'] - event['start']\n",
    "                }\n",
    "                ops_list.append(unfinished_op)\n",
    "                if job_ready is None:\n",
    "                    job_ready = current_time\n",
    "        if ops_list:\n",
    "            unfinished_jobs[job] = {\n",
    "                'job_ready': job_ready,\n",
    "                'due_date': jobs_info[job]['due_date'],\n",
    "                'operations': ops_list\n",
    "            }\n",
    "    return finished_events, unfinished_jobs\n",
    "\n",
    "# Các hàm reschedule heuristic cho phần unfinished:\n",
    "def reschedule_unfinished_jobs_edd(unfinished_jobs, current_time, finished_events, machine_pool):\n",
    "    # Áp dụng EDD nhưng có thể kết hợp thêm processing time\n",
    "    sorted_jobs = sorted(unfinished_jobs.items(), key=lambda x: (x[1]['due_date'], sum(op['processing_time'] for op in x[1]['operations'])))\n",
    "    new_events = []\n",
    "    machine_ready = {m: current_time for m in machine_pool}\n",
    "    for job, info in sorted_jobs:\n",
    "        job_ready = info['job_ready']\n",
    "        for op in sorted(info['operations'], key=lambda op: op['op_index']):\n",
    "            pt = op['processing_time']\n",
    "            best_start = float('inf')\n",
    "            best_finish = float('inf')\n",
    "            best_machine = None\n",
    "            for m in op['candidate_machines']:\n",
    "                st = max(job_ready, machine_ready.get(m, current_time))\n",
    "                ft = st + pt\n",
    "                if ft < best_finish:\n",
    "                    best_finish = ft\n",
    "                    best_start = st\n",
    "                    best_machine = m\n",
    "            event = {\n",
    "                'job': job,\n",
    "                'op_index': op['op_index'],\n",
    "                'start': best_start,\n",
    "                'finish': best_finish,\n",
    "                'machine': best_machine,\n",
    "                'op_id': op['op_id'],\n",
    "                'candidate_machines': op['candidate_machines']\n",
    "            }\n",
    "            new_events.append(event)\n",
    "            job_ready = best_finish\n",
    "            machine_ready[best_machine] = best_finish\n",
    "    return new_events\n",
    "\n",
    "def reschedule_unfinished_jobs_sa(unfinished_jobs, current_time, finished_events, machine_pool, iterations=50):\n",
    "    # Sử dụng SA với cooling schedule động và số iterations cao hơn.\n",
    "    current_solution = reschedule_unfinished_jobs_edd(unfinished_jobs, current_time, finished_events, machine_pool)\n",
    "    current_cost = max(e['finish'] for e in (finished_events + current_solution))\n",
    "    T = 100  # Nhiệt độ khởi đầu\n",
    "    cooling_rate = 0.95\n",
    "    best_solution = current_solution\n",
    "    best_cost = current_cost\n",
    "    for i in range(iterations):\n",
    "        # Tạo neighbor bằng cách thay đổi ngẫu nhiên một vài event trong current_solution\n",
    "        neighbor = copy.deepcopy(current_solution)\n",
    "        # Ví dụ: thay đổi finish của một event\n",
    "        if neighbor:\n",
    "            idx = random.randint(0, len(neighbor)-1)\n",
    "            neighbor[idx]['finish'] *= random.uniform(1.0, 1.05)\n",
    "        merged = finished_events + neighbor\n",
    "        makespan = max(e['finish'] for e in merged) if merged else 0\n",
    "        new_cost = makespan  # Giả sử tardiness không thay đổi\n",
    "        if new_cost < best_cost or random.random() < math.exp(-(new_cost - current_cost)/T):\n",
    "            current_solution = neighbor\n",
    "            current_cost = new_cost\n",
    "            if new_cost < best_cost:\n",
    "                best_solution = neighbor\n",
    "                best_cost = new_cost\n",
    "        T *= cooling_rate\n",
    "    return best_solution\n",
    "\n",
    "def reschedule_unfinished_jobs_ga(unfinished_jobs, current_time, finished_events, machine_pool, num_candidates=10, generations=5):\n",
    "    # Khởi tạo quần thể ban đầu từ hàm EDD\n",
    "    population = [reschedule_unfinished_jobs_edd(unfinished_jobs, current_time, finished_events, machine_pool) for _ in range(num_candidates)]\n",
    "    def evaluate(solution):\n",
    "        merged = finished_events + solution\n",
    "        return max(e['finish'] for e in merged)  # makespan\n",
    "    for gen in range(generations):\n",
    "        # Selection: chọn top 50% cá thể tốt nhất\n",
    "        population = sorted(population, key=evaluate)[:max(1, num_candidates//2)]\n",
    "        new_population = []\n",
    "        # Crossover: tạo ra các cá thể mới từ các cặp\n",
    "        while len(new_population) < num_candidates:\n",
    "            parent1, parent2 = random.sample(population, 2)\n",
    "            child = []\n",
    "            for e1, e2 in zip(parent1, parent2):\n",
    "                child.append(e1 if random.random() < 0.5 else e2)\n",
    "            new_population.append(child)\n",
    "        # Mutation: thay đổi ngẫu nhiên một vài event trong mỗi cá thể\n",
    "        for solution in new_population:\n",
    "            if random.random() < 0.3:\n",
    "                idx = random.randint(0, len(solution)-1)\n",
    "                solution[idx]['finish'] *= random.uniform(0.95, 1.05)\n",
    "        population = new_population\n",
    "    best_solution = min(population, key=evaluate)\n",
    "    return best_solution\n",
    "\n",
    "def reschedule_unfinished_jobs_pso(unfinished_jobs, current_time, finished_events, machine_pool, num_particles=10, iterations=20):\n",
    "    # Định nghĩa hàm cost: ở đây ta sử dụng makespan của lịch trình (merged)\n",
    "    def cost_function(candidate):\n",
    "        merged = finished_events + candidate\n",
    "        return max(e['finish'] for e in merged) if merged else 0\n",
    "\n",
    "    # Khởi tạo population (các candidate solution) dựa trên kết quả EDD có nhiễu\n",
    "    particles = []\n",
    "    velocities = []\n",
    "    base_candidate = reschedule_unfinished_jobs_edd(unfinished_jobs, current_time, finished_events, machine_pool)\n",
    "    for i in range(num_particles):\n",
    "        candidate = copy.deepcopy(base_candidate)\n",
    "        # Thêm nhiễu cho mỗi candidate\n",
    "        for event in candidate:\n",
    "            event['finish'] *= random.uniform(0.95, 1.05)\n",
    "        particles.append(candidate)\n",
    "        velocities.append([0]*len(candidate))\n",
    "\n",
    "    pbest = copy.deepcopy(particles)\n",
    "    pbest_costs = [cost_function(p) for p in particles]\n",
    "    gbest = min(particles, key=cost_function)\n",
    "    gbest_cost = cost_function(gbest)\n",
    "\n",
    "    w = 0.5    # inertia weight\n",
    "    c1 = 1.0   # cognitive coefficient\n",
    "    c2 = 1.0   # social coefficient\n",
    "\n",
    "    # PSO loop\n",
    "    for it in range(iterations):\n",
    "        for i in range(num_particles):\n",
    "            for j in range(len(particles[i])):\n",
    "                current_finish = particles[i][j]['finish']\n",
    "                pbest_finish = pbest[i][j]['finish']\n",
    "                gbest_finish = gbest[j]['finish']\n",
    "                r1 = random.random()\n",
    "                r2 = random.random()\n",
    "                new_velocity = w * velocities[i][j] + c1 * r1 * (pbest_finish - current_finish) + c2 * r2 * (gbest_finish - current_finish)\n",
    "                velocities[i][j] = new_velocity\n",
    "                particles[i][j]['finish'] = current_finish + new_velocity\n",
    "            cost_candidate = cost_function(particles[i])\n",
    "            if cost_candidate < pbest_costs[i]:\n",
    "                pbest[i] = copy.deepcopy(particles[i])\n",
    "                pbest_costs[i] = cost_candidate\n",
    "        candidate_costs = [cost_function(p) for p in particles]\n",
    "        min_cost = min(candidate_costs)\n",
    "        if min_cost < gbest_cost:\n",
    "            gbest = copy.deepcopy(particles[candidate_costs.index(min_cost)])\n",
    "            gbest_cost = min_cost\n",
    "    return gbest\n",
    "\n",
    "# Hàm tạo unified job info cho các job ban đầu\n",
    "def create_unified_jobs_info(jobs_initial, due_dates_initial):\n",
    "    info = {}\n",
    "    for job, ops in jobs_initial.items():\n",
    "        info[job] = {\n",
    "            'operations': ops,\n",
    "            'due_date': due_dates_initial[job]\n",
    "        }\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicSchedulingEnv(gym.Env):\n",
    "    def __init__(self, lambda_tardiness=1.0):\n",
    "        super(DynamicSchedulingEnv, self).__init__()\n",
    "        self.lambda_tardiness = lambda_tardiness\n",
    "        self.machine_pool = machine_pool\n",
    "        self.jobs_initial = jobs_initial\n",
    "        self.due_dates_initial = due_dates_initial\n",
    "        self.all_jobs_info = create_unified_jobs_info(self.jobs_initial, self.due_dates_initial)\n",
    "        # Tạo initial schedule một lần offline\n",
    "        _, schedule, _, _, _, _ = simulated_annealing(self.jobs_initial, self.due_dates_initial, lambda_tardiness=self.lambda_tardiness)\n",
    "        self.initial_schedule_events = schedule_dict_to_list(schedule, self.all_jobs_info)\n",
    "        # Sử dụng initial schedule cố định cho mỗi episode\n",
    "        self.current_schedule_events = copy.deepcopy(self.initial_schedule_events)\n",
    "        self.current_time = 0\n",
    "        self._generate_dynamic_jobs(num_dynamic=4)\n",
    "        self.current_dynamic_index = 0\n",
    "        self.observation_space = spaces.Box(low=0, high=1000, shape=(3,), dtype=np.float32)\n",
    "        # Mở rộng action space: 0: SA, 1: GA, 2: EDD, 3: PSO\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "    def _generate_dynamic_job(self, job_id, arrival_time, min_ops=1, max_ops=5, min_pt=5, max_pt=50):\n",
    "        # Xác định loại job: 10% chance urgent, 90% normal\n",
    "        if random.random() < 0.25:\n",
    "            job_type = \"Urgent\"\n",
    "            etuf = 1.2\n",
    "        else:\n",
    "            job_type = \"Normal\"\n",
    "            etuf = 1.8\n",
    "        num_ops = random.randint(min_ops, max_ops)\n",
    "        operations = []\n",
    "        total_pt = 0\n",
    "        for i in range(num_ops):\n",
    "            candidate_machines = random.sample(self.machine_pool, k=random.randint(1, min(5, len(self.machine_pool))))\n",
    "            pt = random.randint(min_pt, max_pt)\n",
    "            total_pt += pt\n",
    "            op = {\n",
    "                'op_id': i+1,\n",
    "                'candidate_machines': candidate_machines,\n",
    "                'processing_time': pt\n",
    "            }\n",
    "            operations.append(op)\n",
    "        due_date = math.ceil(arrival_time + total_pt * etuf)\n",
    "        dynamic_job = {\n",
    "            'job_id': job_id,\n",
    "            'arrival_time': arrival_time,\n",
    "            'due_date': due_date,\n",
    "            'operations': operations,\n",
    "            'job_type': job_type\n",
    "        }\n",
    "        return dynamic_job\n",
    "\n",
    "    # Cập nhật hàm _generate_dynamic_jobs để đảm bảo các dynamic job không có arrival_time chung\n",
    "    def _generate_dynamic_jobs(self, num_dynamic=4):\n",
    "        dynamic_jobs_events = []\n",
    "        Eave = 20  # Giá trị trung bình của interarrival time; bạn có thể điều chỉnh\n",
    "        # Tính max_finish dựa trên current_schedule_events\n",
    "        max_finish = max(e['finish'] for e in self.current_schedule_events)\n",
    "        margin = 5  # Margin đảm bảo dynamic job xuất hiện trước khi hệ thống kết thúc\n",
    "        T_max = int(max_finish - margin)\n",
    "        T_min = self.current_time + 5  # dynamic job sẽ không xuất hiện quá sớm\n",
    "        if T_min >= T_max:\n",
    "            T_max = T_min + 10\n",
    "\n",
    "        # Sinh arrival_time cho dynamic job thứ nhất\n",
    "        arrival_time = self.current_time + int(np.random.exponential(scale=Eave))\n",
    "        # Đảm bảo dynamic job thứ nhất có arrival_time nằm trong [T_min, T_max - (num_dynamic-1)]\n",
    "        arrival_time = max(T_min, min(arrival_time, T_max - (num_dynamic - 1)))\n",
    "        for i in range(num_dynamic):\n",
    "            if i > 0:\n",
    "                arrival_time += int(np.random.exponential(scale=Eave))\n",
    "            # Đảm bảo rằng dynamic job thứ i có arrival_time <= T_max - (num_dynamic - i - 1)\n",
    "            max_allowed = T_max - (num_dynamic - i - 1)\n",
    "            if arrival_time > max_allowed:\n",
    "                arrival_time = max_allowed\n",
    "            temp_id = \"Temp\" + str(i+1)\n",
    "            dyn_job = self._generate_dynamic_job(temp_id, arrival_time)\n",
    "            dynamic_jobs_events.append((arrival_time, dyn_job))\n",
    "        dynamic_jobs_events.sort(key=lambda x: x[0])\n",
    "        for i, (arrival_time, dj) in enumerate(dynamic_jobs_events):\n",
    "            dj['job_id'] = \"D\" + str(i+1)\n",
    "        self.dynamic_jobs_events = dynamic_jobs_events\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_time = 0\n",
    "        self.all_jobs_info = create_unified_jobs_info(self.jobs_initial, self.due_dates_initial)\n",
    "        self.current_schedule_events = copy.deepcopy(self.initial_schedule_events)\n",
    "        self._generate_dynamic_jobs(num_dynamic=4)\n",
    "        self.current_dynamic_index = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        finished_events, unfinished_jobs = split_schedule_list(self.current_schedule_events, self.current_time, self.all_jobs_info)\n",
    "        num_unfinished = sum(len(info['operations']) for info in unfinished_jobs.values())\n",
    "        total_pt = 0\n",
    "        count = 0\n",
    "        for info in unfinished_jobs.values():\n",
    "            for op in info['operations']:\n",
    "                total_pt += op['processing_time']\n",
    "                count += 1\n",
    "        avg_pt = total_pt / count if count > 0 else 0\n",
    "        return np.array([self.current_time, num_unfinished, avg_pt], dtype=np.float32)\n",
    "\n",
    "    def get_metrics(self):\n",
    "            # Tính các chỉ số từ current_schedule_events\n",
    "            merged = self.current_schedule_events\n",
    "            makespan = max(e['finish'] for e in merged) if merged else 0\n",
    "            total_tardiness_normal = 0\n",
    "            total_tardiness_urgent = 0\n",
    "            for job, info in self.all_jobs_info.items():\n",
    "                job_events = [e for e in merged if e['job'] == job]\n",
    "                if job_events:\n",
    "                    comp_time = max(e['finish'] for e in job_events)\n",
    "                    tardiness = max(0, comp_time - info['due_date'])\n",
    "                    if isinstance(job, int):\n",
    "                        total_tardiness_normal += tardiness\n",
    "                    else:\n",
    "                        if info.get('job_type', 'Normal') == 'Urgent':\n",
    "                            total_tardiness_urgent += tardiness\n",
    "                        else:\n",
    "                            total_tardiness_normal += tardiness\n",
    "            return {\"makespan\": makespan, \"tardiness_normal\": total_tardiness_normal, \"tardiness_urgent\": total_tardiness_urgent}\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_dynamic_index >= len(self.dynamic_jobs_events):\n",
    "            return self._get_state(), 0, True, {}\n",
    "        arrival_time, dyn_job = self.dynamic_jobs_events[self.current_dynamic_index]\n",
    "        self.current_time = arrival_time\n",
    "\n",
    "        finished_events, unfinished_jobs = split_schedule_list(self.current_schedule_events, self.current_time, self.all_jobs_info)\n",
    "\n",
    "        dyn_info = {\n",
    "            'job_ready': self.current_time,\n",
    "            'due_date': dyn_job['due_date'],\n",
    "            'operations': [{'op_index': i, 'op_id': op['op_id'], 'candidate_machines': op['candidate_machines'], 'processing_time': op['processing_time']}\n",
    "                           for i, op in enumerate(dyn_job['operations'])]\n",
    "        }\n",
    "        self.all_jobs_info[dyn_job['job_id']] = dyn_info\n",
    "        unfinished_jobs[dyn_job['job_id']] = dyn_info\n",
    "\n",
    "        if action == 0:\n",
    "            new_unfinished_events = reschedule_unfinished_jobs_sa(unfinished_jobs, self.current_time, finished_events, self.machine_pool)\n",
    "        elif action == 1:\n",
    "            new_unfinished_events = reschedule_unfinished_jobs_ga(unfinished_jobs, self.current_time, finished_events, self.machine_pool)\n",
    "        elif action == 2:\n",
    "            new_unfinished_events = reschedule_unfinished_jobs_edd(unfinished_jobs, self.current_time, finished_events, self.machine_pool)\n",
    "        else:\n",
    "            new_unfinished_events = reschedule_unfinished_jobs_pso(unfinished_jobs, self.current_time, finished_events, self.machine_pool)\n",
    "\n",
    "        self.current_schedule_events = finished_events + new_unfinished_events\n",
    "\n",
    "        merged = self.current_schedule_events\n",
    "        makespan = max(e['finish'] for e in merged) if merged else 0\n",
    "        total_tardiness_normal = 0\n",
    "        total_tardiness_urgent = 0\n",
    "        for job, info in self.all_jobs_info.items():\n",
    "            job_events = [e for e in merged if e['job'] == job]\n",
    "            if job_events:\n",
    "                comp_time = max(e['finish'] for e in job_events)\n",
    "                tardiness = max(0, comp_time - info['due_date'])\n",
    "                if isinstance(job, int):\n",
    "                    total_tardiness_normal += tardiness\n",
    "                else:\n",
    "                    if info.get('job_type', 'Normal') == 'Urgent':\n",
    "                        total_tardiness_urgent += tardiness\n",
    "                    else:\n",
    "                        total_tardiness_normal += tardiness\n",
    "        alpha = 0.75\n",
    "        cost = makespan\n",
    "        reward = -cost\n",
    "\n",
    "        self.current_dynamic_index += 1\n",
    "        done = self.current_dynamic_index >= len(self.dynamic_jobs_events)\n",
    "        next_state = self._get_state()\n",
    "        return next_state, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOActorCritic(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super(PPOActorCritic, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.policy_head = nn.Linear(64, act_dim)\n",
    "        self.value_head = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        logits = self.policy_head(x)\n",
    "        value = self.value_head(x)\n",
    "        return logits, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(model, state):\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    logits, value = model(state_tensor)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    dist = torch.distributions.Categorical(probs)\n",
    "    action = dist.sample()\n",
    "    return action.item(), dist.log_prob(action), value\n",
    "\n",
    "def compute_returns(rewards, masks, gamma=0.9):\n",
    "    returns = []\n",
    "    R = 0\n",
    "    for r, mask in zip(reversed(rewards), reversed(masks)):\n",
    "        R = r + gamma * R * mask\n",
    "        returns.insert(0, R)\n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000  # Số lượng episode training\n",
    "ppo_epochs = 10\n",
    "clip_epsilon = 0.25\n",
    "lr = 3e-4\n",
    "gamma = 0.9\n",
    "entropy_coef = 0.01\n",
    "\n",
    "env = DynamicSchedulingEnv(lambda_tardiness=1.0)  # Số lượng dynamic job có thể thay đổi qua tham số\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n\n",
    "\n",
    "model = PPOActorCritic(obs_dim, act_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Mapping cho tên action\n",
    "action_names = {0: \"SA\", 1: \"GA\", 2: \"EDD\", 3: \"PSO\"}\n",
    "\n",
    "episode_rewards = []        # Tổng reward của mỗi episode\n",
    "policy_loss_history = []      # Trung bình policy loss mỗi episode\n",
    "value_loss_history = []       # Trung bình value loss mỗi episode\n",
    "\n",
    "# Mở file để ghi kết quả (ghi đè file cũ nếu có)\n",
    "with open(\"training_results_I10_E20.txt\", \"w\") as result_file:\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "\n",
    "        print(f\"\\n--- Episode {episode+1} ---\")\n",
    "        print(\"Initial Schedule:\")\n",
    "        for event in env.current_schedule_events:\n",
    "            print({\n",
    "                'job': event['job'],\n",
    "                'op_index': event['op_index'],\n",
    "                'start': round(event['start'], 2),\n",
    "                'finish': round(event['finish'], 2),\n",
    "                'machine': event['machine'],\n",
    "                'op_id': event['op_id'],\n",
    "                'candidate_machines': event['candidate_machines']\n",
    "            })\n",
    "\n",
    "        log_probs_list = []\n",
    "        values_list = []\n",
    "        rewards = []\n",
    "        masks = []\n",
    "        actions_list = []\n",
    "        states_list = []\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        while not done:\n",
    "            action, log_prob, value = select_action(model, state)\n",
    "            print(f\"\\nStep {step_count+1}: Chosen Action: {action_names[action]}\")\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            dyn_index = env.current_dynamic_index - 1\n",
    "            if 0 <= dyn_index < len(env.dynamic_jobs_events):\n",
    "                arrival_time, dyn_job = env.dynamic_jobs_events[dyn_index]\n",
    "                print(f\"\\nDynamic Job Added (arrival_time: {round(arrival_time,2)}):\")\n",
    "                # Làm tròn các giá trị thời gian nếu có\n",
    "                dj_print = dyn_job.copy()\n",
    "                dj_print['arrival_time'] = round(dj_print['arrival_time'], 2)\n",
    "                dj_print['due_date'] = round(dj_print['due_date'], 2)\n",
    "                print(dj_print)\n",
    "            print(\"Final Schedule after reschedule:\")\n",
    "            for event in env.current_schedule_events:\n",
    "                print({\n",
    "                    'job': event['job'],\n",
    "                    'op_index': event['op_index'],\n",
    "                    'start': round(event['start'], 2),\n",
    "                    'finish': round(event['finish'], 2),\n",
    "                    'machine': event['machine'],\n",
    "                    'op_id': event['op_id'],\n",
    "                    'candidate_machines': event['candidate_machines']\n",
    "                })\n",
    "\n",
    "            log_probs_list.append(log_prob)\n",
    "            values_list.append(value)\n",
    "            rewards.append(reward)\n",
    "            masks.append(1 - float(done))\n",
    "            actions_list.append(action)\n",
    "            states_list.append(state)\n",
    "            state = next_state\n",
    "            step_count += 1\n",
    "\n",
    "        # Sau khi episode kết thúc, in các metric\n",
    "        metrics = env.get_metrics()\n",
    "        print(\"\\nEpisode Metrics:\")\n",
    "        print(f\"Makespan: {round(metrics['makespan'], 2)}\")\n",
    "        print(f\"Tardiness Normal: {round(metrics['tardiness_normal'], 2)}\")\n",
    "        print(f\"Tardiness Urgent: {round(metrics['tardiness_urgent'], 2)}\")\n",
    "\n",
    "        total_reward = sum(rewards)\n",
    "        print(f\"Episode {episode+1}, Total Reward: {round(total_reward, 2)}\")\n",
    "\n",
    "        # Ghi kết quả ra file\n",
    "        result_file.write(f\"Episode {episode+1}:\\n\")\n",
    "        result_file.write(f\"Total Reward: {round(total_reward, 2)}\\n\")\n",
    "        result_file.write(f\"Makespan: {round(metrics['makespan'], 2)}\\n\")\n",
    "        result_file.write(f\"Tardiness Normal: {round(metrics['tardiness_normal'], 2)}\\n\")\n",
    "        result_file.write(f\"Tardiness Urgent: {round(metrics['tardiness_urgent'], 2)}\\n\")\n",
    "        result_file.write(\"Dynamic Jobs in this episode:\\n\")\n",
    "        for arrival_time, dyn_job in env.dynamic_jobs_events:\n",
    "            result_file.write(f\"  Arrival Time: {round(arrival_time,2)} - {dyn_job}\\n\")\n",
    "        result_file.write(\"=\"*40 + \"\\n\")\n",
    "\n",
    "        returns = compute_returns(rewards, masks, gamma)\n",
    "        states_np = np.array(states_list)\n",
    "        states = torch.FloatTensor(states_np)\n",
    "        actions = torch.LongTensor(actions_list)\n",
    "        log_probs = torch.stack(log_probs_list).detach()\n",
    "        values = torch.stack(values_list).squeeze().detach()\n",
    "        returns = torch.FloatTensor(returns)\n",
    "\n",
    "        advantage = returns - values\n",
    "        \n",
    "        total_policy_loss = 0.0\n",
    "        total_value_loss = 0.0\n",
    "        count_updates = 0\n",
    "\n",
    "        for _ in range(ppo_epochs):\n",
    "            logits, value_est = model(states)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            dist = torch.distributions.Categorical(probs)\n",
    "            new_log_probs = dist.log_prob(actions)\n",
    "            ratio = torch.exp(new_log_probs - log_probs)\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_epsilon, 1.0 + clip_epsilon) * advantage\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "            value_loss = nn.MSELoss()(value_est.squeeze(), returns)\n",
    "            entropy = dist.entropy().mean()\n",
    "            loss = policy_loss - entropy_coef * entropy + 0.5 * value_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_policy_loss += policy_loss.item()\n",
    "            total_value_loss += value_loss.item()\n",
    "            count_updates += 1\n",
    "            \n",
    "        avg_policy_loss = total_policy_loss / count_updates if count_updates > 0 else 0\n",
    "        avg_value_loss = total_value_loss / count_updates if count_updates > 0 else 0\n",
    "\n",
    "        policy_loss_history.append(avg_policy_loss)\n",
    "        value_loss_history.append(avg_value_loss)\n",
    "        episode_rewards.append(total_reward)\n",
    "\n",
    "torch.save(model.state_dict(), \"trained_policy_I10_E20_test.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Khởi tạo môi trường\n",
    "env = DynamicSchedulingEnv(lambda_tardiness=1.0)\n",
    "# Lấy các thông số từ environment\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n\n",
    "\n",
    "# Định nghĩa mapping cho tên action nếu chưa có\n",
    "action_names = {0: \"SA\", 1: \"GA\", 2: \"EDD\", 3: \"PSO\"}\n",
    "\n",
    "# Tạo model và load trọng số đã huấn luyện\n",
    "model = PPOActorCritic(obs_dim, act_dim)\n",
    "model.load_state_dict(torch.load(\"trained_policy_I10_E20_test.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Hàm vẽ Gantt chart (nếu chưa có)\n",
    "def plot_gantt(schedule_events):\n",
    "    colors = plt.cm.tab20.colors\n",
    "    job_colors = {}\n",
    "    def get_job_color(job):\n",
    "        job = str(job)\n",
    "        if job not in job_colors:\n",
    "            index = len(job_colors) % len(colors)\n",
    "            job_colors[job] = colors[index]\n",
    "        return job_colors[job]\n",
    "    machines = {}\n",
    "    for event in schedule_events:\n",
    "        m = event['machine']\n",
    "        machines.setdefault(m, []).append(event)\n",
    "    machine_ids = sorted(machines.keys())\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    yticks = []\n",
    "    ytick_labels = []\n",
    "    bar_height = 0.8\n",
    "    for i, m in enumerate(machine_ids):\n",
    "        yticks.append(i)\n",
    "        ytick_labels.append(f\"Machine {m}\")\n",
    "        events = sorted(machines[m], key=lambda e: e['start'])\n",
    "        for event in events:\n",
    "            start = event['start']\n",
    "            finish = event['finish']\n",
    "            duration = finish - start\n",
    "            job = event['job']\n",
    "            color = get_job_color(job)\n",
    "            ax.barh(i, duration, left=start, height=bar_height, align='center', color=color, edgecolor='black')\n",
    "            ax.text(start + duration/2, i, f\"{job}\", color='black', ha='center', va='center', fontsize=10)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ytick_labels, fontsize=12)\n",
    "    ax.set_xlabel(\"Time\", fontsize=14)\n",
    "    ax.set_title(\"Gantt Chart for Final Episode Schedule\", fontsize=16)\n",
    "    max_finish = max(e['finish'] for e in schedule_events) if schedule_events else 0\n",
    "    ax.set_xlim(0, max_finish + 10)\n",
    "    def sort_key(job_id):\n",
    "        try:\n",
    "            return (0, int(job_id))\n",
    "        except ValueError:\n",
    "            if job_id.startswith(\"D\"):\n",
    "                return (1, int(job_id[1:]))\n",
    "            return (1, job_id)\n",
    "    sorted_jobs = sorted(job_colors.items(), key=lambda item: sort_key(item[0]))\n",
    "    legend_elements = [Patch(facecolor=color, edgecolor='black', label=f\"Job {job}\") for job, color in sorted_jobs]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0.)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Inference: sử dụng model đã huấn luyện để chạy một episode thực tế\n",
    "state = env.reset()\n",
    "done = False\n",
    "dynamic_jobs_info = []\n",
    "\n",
    "while not done:\n",
    "    action, log_prob, value = select_action(model, state)\n",
    "    chosen_action = action_names[action]\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    dyn_index = env.current_dynamic_index - 1\n",
    "    if 0 <= dyn_index < len(env.dynamic_jobs_events):\n",
    "        arrival_time, dyn_job = env.dynamic_jobs_events[dyn_index]\n",
    "        dynamic_jobs_info.append({\n",
    "            \"arrival_time\": round(arrival_time, 2),\n",
    "            \"job\": dyn_job\n",
    "        })\n",
    "        print(f\"\\nDynamic Job Added (arrival_time: {round(arrival_time,2)})\")\n",
    "        print(dyn_job)\n",
    "    state = next_state\n",
    "\n",
    "# Sau khi episode kết thúc, in ra các metric và lịch trình\n",
    "metrics = env.get_metrics()\n",
    "print(\"\\nFinal Metrics:\")\n",
    "print(f\"Makespan: {round(metrics['makespan'],2)}\")\n",
    "print(f\"Tardiness Normal: {round(metrics['tardiness_normal'],2)}\")\n",
    "print(f\"Tardiness Urgent: {round(metrics['tardiness_urgent'],2)}\")\n",
    "\n",
    "print(\"\\nDynamic Jobs in this Episode:\")\n",
    "for dj in dynamic_jobs_info:\n",
    "    print(f\"Arrival Time: {dj['arrival_time']} -> Job Info: {dj['job']}\")\n",
    "\n",
    "print(\"\\nFinal Schedule:\")\n",
    "for event in env.current_schedule_events:\n",
    "    print({\n",
    "        'job': event['job'],\n",
    "        'op_index': event['op_index'],\n",
    "        'start': round(event['start'], 2),\n",
    "        'finish': round(event['finish'], 2),\n",
    "        'machine': event['machine'],\n",
    "        'op_id': event['op_id'],\n",
    "        'candidate_machines': event['candidate_machines']\n",
    "    })\n",
    "\n",
    "# Vẽ Gantt Chart cho lịch trình cuối cùng\n",
    "plot_gantt(env.current_schedule_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell: In và vẽ lịch trình ban đầu cho các job tĩnh ---\n",
    "\n",
    "# Tạo thông tin tổng hợp cho các job ban đầu\n",
    "all_jobs_info = create_unified_jobs_info(jobs_initial, due_dates_initial)\n",
    "\n",
    "# Tạo lịch trình ban đầu sử dụng simulated_annealing cho các job tĩnh\n",
    "_, initial_schedule, makespan, total_tardiness, cost, _ = simulated_annealing(jobs_initial, due_dates_initial, lambda_tardiness=1.0)\n",
    "\n",
    "# Chuyển đổi lịch trình từ dạng dictionary sang dạng list các event\n",
    "initial_schedule_events = schedule_dict_to_list(initial_schedule, all_jobs_info)\n",
    "\n",
    "print(\"Initial Schedule for Initial Jobs:\")\n",
    "for event in initial_schedule_events:\n",
    "    print({\n",
    "         'job': event['job'],\n",
    "         'op_index': event['op_index'],\n",
    "         'start': round(event['start'], 2),\n",
    "         'finish': round(event['finish'], 2),\n",
    "         'machine': event['machine'],\n",
    "         'op_id': event['op_id'],\n",
    "         'candidate_machines': event['candidate_machines']\n",
    "    })\n",
    "\n",
    "# Định nghĩa hàm vẽ Gantt Chart (nếu chưa có)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def plot_gantt(schedule_events):\n",
    "    colors = plt.cm.tab20.colors\n",
    "    job_colors = {}\n",
    "    \n",
    "    def get_job_color(job):\n",
    "        job = str(job)\n",
    "        if job not in job_colors:\n",
    "            index = len(job_colors) % len(colors)\n",
    "            job_colors[job] = colors[index]\n",
    "        return job_colors[job]\n",
    "    \n",
    "    # Nhóm các event theo machine\n",
    "    machines = {}\n",
    "    for event in schedule_events:\n",
    "        m = event['machine']\n",
    "        machines.setdefault(m, []).append(event)\n",
    "    \n",
    "    machine_ids = sorted(machines.keys())\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    \n",
    "    yticks = []\n",
    "    ytick_labels = []\n",
    "    bar_height = 0.8\n",
    "    \n",
    "    for i, m in enumerate(machine_ids):\n",
    "        yticks.append(i)\n",
    "        ytick_labels.append(f\"Machine {m}\")\n",
    "        events = sorted(machines[m], key=lambda e: e['start'])\n",
    "        for event in events:\n",
    "            start = event['start']\n",
    "            finish = event['finish']\n",
    "            duration = finish - start\n",
    "            job = event['job']\n",
    "            color = get_job_color(job)\n",
    "            ax.barh(i, duration, left=start, height=bar_height, align='center', color=color, edgecolor='black')\n",
    "            ax.text(start + duration/2, i, f\"{job}\", color='black', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ytick_labels, fontsize=12)\n",
    "    ax.set_xlabel(\"Time\", fontsize=14)\n",
    "    ax.set_title(\"Gantt Chart for Initial Schedule\", fontsize=16)\n",
    "    \n",
    "    max_finish = max(e['finish'] for e in schedule_events) if schedule_events else 0\n",
    "    ax.set_xlim(0, max_finish + 10)\n",
    "    \n",
    "    # Sắp xếp legend theo thứ tự: job số trước, sau đó job dạng \"D...\"\n",
    "    def sort_key(job_id):\n",
    "        try:\n",
    "            return (0, int(job_id))\n",
    "        except ValueError:\n",
    "            if job_id.startswith(\"D\"):\n",
    "                return (1, int(job_id[1:]))\n",
    "            return (1, job_id)\n",
    "    \n",
    "    sorted_jobs = sorted(job_colors.items(), key=lambda item: sort_key(item[0]))\n",
    "    legend_elements = [Patch(facecolor=color, edgecolor='black', label=f\"Job {job}\") for job, color in sorted_jobs]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0.)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Vẽ Gantt Chart cho lịch trình ban đầu\n",
    "plot_gantt(initial_schedule_events)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
