# ğŸ“š HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG DATASET KHÃC

## ğŸ¯ TÃ“M Táº®T

Project hiá»‡n cÃ³ **7 datasets khÃ¡c nhau** (tá»« 20 Ä‘áº¿n 50 jobs). Báº¡n cÃ³ thá»ƒ dá»… dÃ ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c datasets báº±ng cÃ¡ch thay Ä‘á»•i **1 dÃ²ng trong `config.py`**.

---

## ğŸ“‚ DATASETS CÃ“ Sáº´N

```
data/
  â”œâ”€â”€ Set20.json  â†’ 20 jobs (default)
  â”œâ”€â”€ Set25.json  â†’ 25 jobs
  â”œâ”€â”€ Set30.json  â†’ 30 jobs
  â”œâ”€â”€ Set35.json  â†’ 35 jobs
  â”œâ”€â”€ Set40.json  â†’ 40 jobs
  â”œâ”€â”€ Set45.json  â†’ 45 jobs
  â””â”€â”€ Set50.json  â†’ 50 jobs
```

### Cáº¥u trÃºc má»—i dataset:
- **Jobs**: Danh sÃ¡ch cÃ´ng viá»‡c vá»›i cÃ¡c operations
- **Machines**: Pool cÃ¡c mÃ¡y mÃ³c kháº£ dá»¥ng
- **Due dates**: Deadline cho má»—i job
- **Processing times**: Thá»i gian xá»­ lÃ½ má»—i operation

---

## âš¡ CÃCH Sá»¬ Dá»¤NG (3 BÆ¯á»šC)

### **BÆ°á»›c 1: Má»Ÿ file `config.py`**

TÃ¬m dÃ²ng nÃ y trong class `EnvironmentConfig` (khoáº£ng dÃ²ng 150):

```python
class EnvironmentConfig:
    """Job Shop Scheduling Environment settings"""
    
    # Dataset selection
    dataset_name = None  # â† ÄÃ‚Y!
```

---

### **BÆ°á»›c 2: Thay Ä‘á»•i `dataset_name`**

#### **Option A: DÃ¹ng dataset máº·c Ä‘á»‹nh (hardcoded - 20 jobs)**
```python
dataset_name = None  # Default
```

#### **Option B: DÃ¹ng Set20 (20 jobs)**
```python
dataset_name = "Set20"
```

#### **Option C: DÃ¹ng Set25 (25 jobs)**
```python
dataset_name = "Set25"
```

#### **Option D: DÃ¹ng Set30 (30 jobs)**
```python
dataset_name = "Set30"
```

#### **Option E: DÃ¹ng Set35 (35 jobs)**
```python
dataset_name = "Set35"
```

#### **Option F: DÃ¹ng Set40 (40 jobs)**
```python
dataset_name = "Set40"
```

#### **Option G: DÃ¹ng Set45 (45 jobs)**
```python
dataset_name = "Set45"
```

#### **Option H: DÃ¹ng Set50 (50 jobs)**
```python
dataset_name = "Set50"
```

---

### **BÆ°á»›c 3: Cháº¡y training nhÆ° bÃ¬nh thÆ°á»ng**

```bash
python run_training.py
```

Hoáº·c:

```bash
python scripts/train_lgp.py
```

---

## ğŸ“Š XEM THÃ”NG TIN DATASET

### **List táº¥t cáº£ datasets:**

```bash
python environment/dataset_loader.py
```

Output:
```
ğŸ“š Available Datasets:
==================================================
  - Set20
  - Set25
  - Set30
  - Set35
  - Set40
  - Set45
  - Set50
==================================================
```

---

### **Xem chi tiáº¿t 1 dataset:**

Má»Ÿ Python console:

```python
from environment.dataset_loader import print_dataset_info

# Xem thÃ´ng tin Set20
print_dataset_info("Set20")
```

Output:
```
ğŸ“Š Dataset Info: Set20
==================================================
  Total Jobs:        20
  Total Machines:    12
  Machine IDs:       [0, 1, 3, 4, 5, 6, 7, 8, 12, 25, 43, 1200]
  Total Operations:  31
  Avg Ops/Job:       1.55
  Unique Due Dates:  1
==================================================
```

---

## ğŸ”§ ADVANCED: LOAD DATASET TRONG CODE

Náº¿u báº¡n muá»‘n load dataset trá»±c tiáº¿p trong code:

```python
from environment.dataset_loader import load_dataset

# Load Set30
jobs, due_dates, machine_pool = load_dataset("Set30")

print(f"Loaded {len(jobs)} jobs")
print(f"Machine pool: {machine_pool}")
```

---

## âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG

### **1. Dataset Size vs Training Time**

| Dataset | Jobs | Approx. Training Time | Complexity |
|---------|------|----------------------|------------|
| Set20   | 20   | Baseline (1x)        | Low        |
| Set25   | 25   | 1.3x                 | Low-Med    |
| Set30   | 30   | 1.5x                 | Medium     |
| Set35   | 35   | 1.8x                 | Med-High   |
| Set40   | 40   | 2.0x                 | High       |
| Set45   | 45   | 2.3x                 | High       |
| Set50   | 50   | 2.5x                 | Very High  |

âš ï¸ **Datasets lá»›n hÆ¡n = thá»i gian training lÃ¢u hÆ¡n!**

---

### **2. Hyperparameter Tuning**

Khi chuyá»ƒn sang dataset lá»›n hÆ¡n, báº¡n NÃŠN Ä‘iá»u chá»‰nh:

#### **Cho Set30-35:**
```python
# config.py
CoevolutionConfig.episodes_per_gen = 500  # TÄƒng tá»« 400
LGPConfig.action_budget_s = 4.0  # TÄƒng tá»« 3.0 (MH cáº§n thá»i gian hÆ¡n)
```

#### **Cho Set40-50:**
```python
# config.py
CoevolutionConfig.episodes_per_gen = 600  # TÄƒng nhiá»u hÆ¡n
LGPConfig.action_budget_s = 5.0  # Cho MH Ä‘á»§ thá»i gian
CoevolutionConfig.num_generations = 25  # TÄƒng sá»‘ generations
```

---

### **3. Fallback Safety**

Náº¿u file dataset **khÃ´ng tá»“n táº¡i** hoáº·c **cÃ³ lá»—i**, há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng:
- âš ï¸ In cáº£nh bÃ¡o
- âœ… Fallback vá» default hardcoded dataset (20 jobs)
- âœ… Tiáº¿p tá»¥c training bÃ¬nh thÆ°á»ng

**VÃ­ dá»¥:**
```python
dataset_name = "Set99"  # File khÃ´ng tá»“n táº¡i

# Output:
# âš ï¸ Dataset file not found: data/Set99.json
#    Falling back to hardcoded default dataset
# âœ… Using hardcoded default dataset (20 jobs)
```

---

## ğŸ§ª TEST DATASETS

### **Quick Test vá»›i táº¥t cáº£ datasets:**

```bash
python environment/dataset_loader.py
```

Script sáº½:
1. List táº¥t cáº£ datasets
2. Load tá»«ng dataset
3. Verify dá»¯ liá»‡u há»£p lá»‡
4. In thÃ´ng tin

---

## ğŸ“ VÃ Dá»¤ THá»°C Táº¾

### **Scenario 1: Training vá»›i Set25**

```python
# config.py
class EnvironmentConfig:
    dataset_name = "Set25"  # â† Thay Ä‘á»•i dÃ²ng nÃ y
    lambda_tardiness = 1.0
    num_dynamic_jobs = 2
```

```bash
python run_training.py
```

Output:
```
âœ… Loaded dataset: Set25
ğŸ­ Creating scheduling environment...
âœ“ Environment created with 25 initial jobs
...
```

---

### **Scenario 2: So sÃ¡nh performance giá»¯a datasets**

```python
# Test 1: Set20
EnvironmentConfig.dataset_name = "Set20"
# Run training â†’ Save results as "results_set20/"

# Test 2: Set30
EnvironmentConfig.dataset_name = "Set30"
# Run training â†’ Save results as "results_set30/"

# Compare makespan, tardiness, etc.
```

---

### **Scenario 3: Progressive training**

Train tá»« dataset nhá» â†’ lá»›n:

```python
# Week 1: Set20 (learn basics)
dataset_name = "Set20"
num_generations = 20

# Week 2: Set30 (scale up)
dataset_name = "Set30"
num_generations = 25

# Week 3: Set50 (final challenge)
dataset_name = "Set50"
num_generations = 30
```

---

## ğŸ¯ KHUYáº¾N NGHá»Š

### **Cho nghiÃªn cá»©u/testing:**
- âœ… DÃ¹ng **Set20** hoáº·c **Set25** (nhanh, dá»… debug)

### **Cho experiments:**
- âœ… DÃ¹ng **Set30** hoáº·c **Set35** (balance tá»‘t)

### **Cho final results/paper:**
- âœ… DÃ¹ng **Set40-50** (thÃ¡ch thá»©c, impressive)

### **Cho quick debugging:**
- âœ… DÃ¹ng **None** (default hardcoded, fastest)

---

## ğŸ› TROUBLESHOOTING

### **Problem 1: Dataset khÃ´ng load Ä‘Æ°á»£c**

```
âŒ Error loading dataset: [Errno 2] No such file or directory
```

**Solution:**
- Kiá»ƒm tra file tá»“n táº¡i trong `data/` directory
- Kiá»ƒm tra tÃªn file Ä‘Ãºng format: `SetXX.json`
- DÃ¹ng `dataset_name = None` Ä‘á»ƒ dÃ¹ng default

---

### **Problem 2: JSON format error**

```
âŒ Error loading dataset: Expecting property name enclosed in double quotes
```

**Solution:**
- File JSON bá»‹ lá»—i format
- Kiá»ƒm tra syntax JSON (dÃ¹ng jsonlint.com)
- Hoáº·c fallback vá» default: `dataset_name = None`

---

### **Problem 3: Training quÃ¡ cháº­m**

**Solution:**
- Giáº£m `episodes_per_gen`
- Giáº£m `num_generations`
- Chuyá»ƒn sang dataset nhá» hÆ¡n
- Giáº£m `action_budget_s`

---

## ğŸ“š THÃŠM DATASET Má»šI

Náº¿u báº¡n muá»‘n thÃªm dataset riÃªng:

### **BÆ°á»›c 1: Táº¡o file JSON**

```json
{
  "name": "MyCustomSet",
  "machine_pool": [1, 2, 3, 4, 5],
  "jobs": {
    "1": [
      {
        "op_id": 1,
        "candidate_machines": [1, 2],
        "processing_time": 10
      }
    ],
    "2": [...]
  },
  "due_dates": {
    "1": 1000,
    "2": 1000
  }
}
```

### **BÆ°á»›c 2: LÆ°u vÃ o `data/MyCustomSet.json`**

### **BÆ°á»›c 3: Sá»­ dá»¥ng**

```python
# config.py
EnvironmentConfig.dataset_name = "MyCustomSet"
```

---

## ğŸ‰ TÃ“M Láº I

1. âœ… **Chá»‰ cáº§n thay Ä‘á»•i 1 dÃ²ng trong `config.py`**
2. âœ… **7 datasets sáºµn cÃ³ (20-50 jobs)**
3. âœ… **Auto fallback náº¿u cÃ³ lá»—i**
4. âœ… **Easy to add custom datasets**
5. âœ… **Backward compatible vá»›i code cÅ©**

**Happy experimenting! ğŸš€**
